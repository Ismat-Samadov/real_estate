# name: Real Estate Scraper

# on:
#   schedule:
#     - cron: '0 * * * *'  # Run every hour
#   workflow_dispatch:      # Allow manual trigger

# jobs:
#   scrape:
#     runs-on: ubuntu-latest
    
#     env:
#       DB_HOST: ${{ secrets.DB_HOST }}
#       DB_USER: ${{ secrets.DB_USER }}
#       DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
#       DB_NAME: ${{ secrets.DB_NAME }}
#       SSL_CERT: ${{ secrets.SSL_CERT }}
#       PORT: '27566'
#       REQUEST_DELAY: '1'
#       MAX_RETRIES: '5'
#       LOGGING_LEVEL: 'DEBUG'  # DEBUG, INFO, WARNING, ERROR, CRITICAL

#     steps:
#       - name: Checkout code
#         uses: actions/checkout@v3

#       - name: Set up Python
#         uses: actions/setup-python@v4
#         with:
#           python-version: '3.10'
#           cache: 'pip'

#       - name: Install dependencies
#         run: |
#           python -m pip install --upgrade pip
#           pip install -r requirements.txt

#       - name: Verify environment
#         run: |
#           echo "Checking environment variables (sanitized)..."
#           echo "DB_HOST set: ${{ secrets.DB_HOST != '' }}"
#           echo "DB_USER set: ${{ secrets.DB_USER != '' }}"
#           echo "SSL_CERT length: ${#SSL_CERT}"

#       - name: Run scraper
#         run: python main.py

#       - name: Upload logs
#         if: always()
#         uses: actions/upload-artifact@v4
#         with:
#           name: scraper-logs
#           path: logs/scraper.log
#           retention-days: 7