name: Deploy Real Estate Scraper

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    env:
      SERVER_IP: ${{ secrets.SERVER_IP }}
      SERVER_USER: ${{ secrets.SERVER_USER }}
      DB_NAME: ${{ secrets.DB_NAME }}
      DB_HOST: ${{ secrets.DB_HOST }}
      DB_USER: ${{ secrets.DB_USER }}
      DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
      DB_PORT: ${{ secrets.DB_PORT }}
      REQUEST_DELAY: ${{ secrets.REQUEST_DELAY }}
      MAX_RETRIES: ${{ secrets.MAX_RETRIES }}
      LOGGING_LEVEL: ${{ secrets.LOGGING_LEVEL }}
      SCRAPER_PAGES: ${{ secrets.SCRAPER_PAGES }}
      PROXY_USERNAME: ${{ secrets.PROXY_USERNAME }}
      PROXY_PASSWORD: ${{ secrets.PROXY_PASSWORD }}
      TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
      TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install SSH key
        run: |
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" | tr -d '\r' > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -H "${{ secrets.SERVER_IP }}" >> ~/.ssh/known_hosts

      - name: Create Directory Structure
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_IP }} '
            # Create necessary directories
            sudo mkdir -p /var/www/scraper
            sudo mkdir -p /var/www/scraper/logs
            sudo chown -R $USER:$USER /var/www/scraper
          '

      - name: Backup Existing Environment
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_IP }} '
            if [ -d "/var/www/scraper/venv" ]; then
              mv /var/www/scraper/venv /var/www/scraper/venv_backup
            fi
            rm -rf /var/www/scraper/*
            if [ -d "/var/www/scraper/venv_backup" ]; then
              mv /var/www/scraper/venv_backup /var/www/scraper/venv
            fi
          '

      - name: Setup Supervisor
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_IP }} '
            # Stop and clean existing supervisor processes
            sudo supervisorctl stop all || true
            sudo systemctl stop supervisord || true
            sudo pkill supervisord || true
            sudo rm -f /etc/supervisord.d/*.ini

            # Create supervisor config
            sudo tee /etc/supervisord.d/realestate_scraper.ini << EOF
[program:realestate_scraper]
command=/var/www/scraper/venv/bin/python /var/www/scraper/main.py
directory=/var/www/scraper
user=$USER
autostart=true
autorestart=true
startretries=3
startsecs=10
redirect_stderr=true
stdout_logfile=/var/www/scraper/logs/supervisor.log
stderr_logfile=/var/www/scraper/logs/supervisor.err.log
environment=PYTHONPATH="/var/www/scraper",PYTHONUNBUFFERED="1"
EOF

            # Update main supervisor config if needed
            sudo grep -q "^\[include\]" /etc/supervisord.conf || echo -e "\n[include]\nfiles = /etc/supervisord.d/*.ini" | sudo tee -a /etc/supervisord.conf
          '

      - name: Deploy Application Files
        run: |
          # Create environment file
          echo "DB_NAME=${{ secrets.DB_NAME }}" > .env
          echo "DB_HOST=${{ secrets.DB_HOST }}" >> .env
          echo "DB_USER=${{ secrets.DB_USER }}" >> .env
          echo "DB_PASSWORD=${{ secrets.DB_PASSWORD }}" >> .env
          echo "DB_PORT=${{ secrets.DB_PORT }}" >> .env
          echo "REQUEST_DELAY=${{ secrets.REQUEST_DELAY }}" >> .env
          echo "MAX_RETRIES=${{ secrets.MAX_RETRIES }}" >> .env
          echo "LOGGING_LEVEL=${{ secrets.LOGGING_LEVEL }}" >> .env
          echo "SCRAPER_PAGES=${{ secrets.SCRAPER_PAGES }}" >> .env
          echo "PROXY_USERNAME=${{ secrets.PROXY_USERNAME }}" >> .env
          echo "PROXY_PASSWORD=${{ secrets.PROXY_PASSWORD }}" >> .env
          echo "TELEGRAM_BOT_TOKEN=${{ secrets.TELEGRAM_BOT_TOKEN }}" >> .env
          echo "TELEGRAM_CHAT_ID=${{ secrets.TELEGRAM_CHAT_ID }}" >> .env

          # Create deployment package
          tar czf deploy.tar.gz \
            --exclude='.git' \
            --exclude='.github' \
            --exclude='*.pyc' \
            --exclude='__pycache__' \
            LICENSE README.md main.py utils.py proxy_handler.py \
            telegram_reporter.py requirements.txt .env \
            scrapers/

          # Upload package
          scp -i ~/.ssh/deploy_key deploy.tar.gz ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_IP }}:/var/www/scraper/

      - name: Install and Configure
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_IP }} '
            cd /var/www/scraper &&
            tar xzf deploy.tar.gz &&
            rm deploy.tar.gz &&
            chmod 600 .env &&
            
            # Setup Python environment
            if [ ! -d "venv" ]; then
              python3 -m venv venv
              source venv/bin/activate
              pip install --upgrade pip
              pip install -r requirements.txt
              deactivate
            fi
            
            # Set permissions
            sudo chown -R $USER:$USER /var/www/scraper
            sudo chmod -R 755 /var/www/scraper
            sudo chmod 600 /var/www/scraper/.env
          '

      - name: Start Services
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_IP }} '
            # Restart and enable supervisor
            sudo systemctl enable supervisord
            sudo systemctl restart supervisord
            sleep 5
            
            # Start our application
            sudo supervisorctl reread
            sudo supervisorctl update
            sudo supervisorctl restart realestate_scraper
            
            # Verify status
            sudo supervisorctl status realestate_scraper
          '