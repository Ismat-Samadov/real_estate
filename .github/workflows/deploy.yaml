name: Deploy Real Estate Scraper

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    env:
      SERVER_IP: ${{ secrets.SERVER_IP }}
      SERVER_USER: ${{ secrets.SERVER_USER }}
      DB_NAME: ${{ secrets.DB_NAME }}
      DB_HOST: ${{ secrets.DB_HOST }}
      DB_USER: ${{ secrets.DB_USER }}
      DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
      DB_PORT: ${{ secrets.DB_PORT }}
      REQUEST_DELAY: ${{ secrets.REQUEST_DELAY }}
      MAX_RETRIES: ${{ secrets.MAX_RETRIES }}
      LOGGING_LEVEL: ${{ secrets.LOGGING_LEVEL }}
      SCRAPER_PAGES: ${{ secrets.SCRAPER_PAGES }}
      BRIGHT_DATA_USERNAME: ${{ secrets.BRIGHT_DATA_USERNAME }}
      BRIGHT_DATA_PASSWORD: ${{ secrets.BRIGHT_DATA_PASSWORD }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install SSH key
        run: |
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" | tr -d '\r' > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -H "${{ secrets.SERVER_IP }}" >> ~/.ssh/known_hosts

      - name: Clean and prepare directory
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_IP }} '
            rm -rf /var/www/scraper/* 
            mkdir -p /var/www/scraper
          '

      - name: Deploy files
        run: |
          tar czf deploy.tar.gz \
            --exclude='.git' \
            --exclude='.github' \
            --exclude='*.pyc' \
            --exclude='__pycache__' \
            LICENSE README.md main.py bright_data_proxy.py requirements.txt schema.sql monitoring.sql \
            scrapers/

          scp -i ~/.ssh/deploy_key deploy.tar.gz ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_IP }}:/var/www/scraper/
          ssh -i ~/.ssh/deploy_key ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_IP }} '
            cd /var/www/scraper && 
            tar xzf deploy.tar.gz &&
            rm deploy.tar.gz &&
            mkdir -p logs
          '
