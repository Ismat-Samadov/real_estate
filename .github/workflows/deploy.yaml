name: Deploy Real Estate Scraper

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    env:
      SSH_KEY: ${{ secrets.SSH_PRIVATE_KEY }}
      SERVER_IP: ${{ secrets.SERVER_IP }}
      SERVER_USER: ${{ secrets.SERVER_USER }}
      DB_NAME: ${{ secrets.DB_NAME }}
      DB_HOST: ${{ secrets.DB_HOST }}
      DB_USER: ${{ secrets.DB_USER }}
      DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
      DB_PORT: ${{ secrets.DB_PORT }}
      REQUEST_DELAY: ${{ secrets.REQUEST_DELAY }}
      MAX_RETRIES: ${{ secrets.MAX_RETRIES }}
      LOGGING_LEVEL: ${{ secrets.LOGGING_LEVEL }}
      SCRAPER_PAGES: ${{ secrets.SCRAPER_PAGES }}
      BRIGHT_DATA_USERNAME: ${{ secrets.BRIGHT_DATA_USERNAME }}
      BRIGHT_DATA_PASSWORD: ${{ secrets.BRIGHT_DATA_PASSWORD }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup SSH
        run: |
          mkdir -p ~/.ssh
          echo "$SSH_KEY" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -H $SERVER_IP >> ~/.ssh/known_hosts

      - name: Create deployment directory
        run: |
          ssh -i ~/.ssh/deploy_key $SERVER_USER@$SERVER_IP '
            mkdir -p /var/www/scraper/new
            rm -rf /var/www/scraper/old
          '

      - name: Deploy application files
        run: |
          # Create tar archive of the application
          tar czf deploy.tar.gz \
            LICENSE README.md main.py bright_data_proxy.py requirements.txt schema.sql monitoring.sql \
            scrapers/

          # Copy and extract files
          scp -i ~/.ssh/deploy_key deploy.tar.gz $SERVER_USER@$SERVER_IP:/var/www/scraper/new/
          ssh -i ~/.ssh/deploy_key $SERVER_USER@$SERVER_IP '
            cd /var/www/scraper/new && 
            tar xzf deploy.tar.gz &&
            rm deploy.tar.gz
          '

      - name: Setup Python environment
        run: |
          ssh -i ~/.ssh/deploy_key $SERVER_USER@$SERVER_IP '
            cd /var/www/scraper/new &&
            python3 -m venv .venv &&
            source .venv/bin/activate &&
            pip install --upgrade pip &&
            pip install -r requirements.txt
          '

      - name: Configure environment variables
        run: |
          ssh -i ~/.ssh/deploy_key $SERVER_USER@$SERVER_IP "
            cat > /var/www/scraper/new/.env << EOL
            DB_NAME=${DB_NAME}
            DB_HOST=${DB_HOST}
            DB_USER=${DB_USER}
            DB_PASSWORD=${DB_PASSWORD}
            DB_PORT=${DB_PORT}
            REQUEST_DELAY=${REQUEST_DELAY}
            MAX_RETRIES=${MAX_RETRIES}
            LOGGING_LEVEL=${LOGGING_LEVEL}
            SCRAPER_PAGES=${SCRAPER_PAGES}
            BRIGHT_DATA_USERNAME=${BRIGHT_DATA_USERNAME}
            BRIGHT_DATA_PASSWORD=${BRIGHT_DATA_PASSWORD}
            EOL

            chmod 600 /var/www/scraper/new/.env
          "

      - name: Rotate deployment
        run: |
          ssh -i ~/.ssh/deploy_key $SERVER_USER@$SERVER_IP '
            if [ -d "/var/www/scraper/current" ]; then
              mv /var/www/scraper/current /var/www/scraper/old
            fi
            mv /var/www/scraper/new /var/www/scraper/current
            rm -rf /var/www/scraper/old
          '

      - name: Set permissions
        run: |
          ssh -i ~/.ssh/deploy_key $SERVER_USER@$SERVER_IP '
            chmod -R 755 /var/www/scraper/current
            mkdir -p /var/www/scraper/current/logs
            chmod 777 /var/www/scraper/current/logs
          '

      - name: Verify deployment
        run: |
          ssh -i ~/.ssh/deploy_key $SERVER_USER@$SERVER_IP '
            cd /var/www/scraper/current &&
            source .venv/bin/activate &&
            python3 -c "from dotenv import load_dotenv; load_dotenv(); import os; print(f\"DB_HOST: {os.getenv(\"DB_HOST\")}\");"
          '