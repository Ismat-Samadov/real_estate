name: Deploy Real Estate Scraper

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    env:
      SERVER_IP: ${{ secrets.SERVER_IP }}
      SERVER_USER: ${{ secrets.SERVER_USER }}
      DB_NAME: ${{ secrets.DB_NAME }}
      DB_HOST: ${{ secrets.DB_HOST }}
      DB_USER: ${{ secrets.DB_USER }}
      DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
      DB_PORT: ${{ secrets.DB_PORT }}
      REQUEST_DELAY: ${{ secrets.REQUEST_DELAY }}
      MAX_RETRIES: ${{ secrets.MAX_RETRIES }}
      LOGGING_LEVEL: ${{ secrets.LOGGING_LEVEL }}
      SCRAPER_PAGES: ${{ secrets.SCRAPER_PAGES }}
      BRIGHT_DATA_USERNAME: ${{ secrets.BRIGHT_DATA_USERNAME }}
      BRIGHT_DATA_PASSWORD: ${{ secrets.BRIGHT_DATA_PASSWORD }}
      PROXY_USERNAME: ${{ secrets.PROXY_USERNAME }}
      PROXY_PASSWORD: ${{ secrets.PROXY_PASSWORD }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install SSH key
        run: |
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" | tr -d '\r' > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -H "${{ secrets.SERVER_IP }}" >> ~/.ssh/known_hosts

      - name: Clean and prepare directory
        run: |
          ssh -i ~/.ssh/deploy_key ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_IP }} '
            rm -rf /var/www/scraper/* 
            mkdir -p /var/www/scraper
          '

      - name: Deploy files
        run: |
          # Create environment file
          echo "DB_NAME=${{ secrets.DB_NAME }}" > .env
          echo "DB_HOST=${{ secrets.DB_HOST }}" >> .env
          echo "DB_USER=${{ secrets.DB_USER }}" >> .env
          echo "DB_PASSWORD=${{ secrets.DB_PASSWORD }}" >> .env
          echo "DB_PORT=${{ secrets.DB_PORT }}" >> .env
          echo "REQUEST_DELAY=${{ secrets.REQUEST_DELAY }}" >> .env
          echo "MAX_RETRIES=${{ secrets.MAX_RETRIES }}" >> .env
          echo "LOGGING_LEVEL=${{ secrets.LOGGING_LEVEL }}" >> .env
          echo "SCRAPER_PAGES=${{ secrets.SCRAPER_PAGES }}" >> .env
          echo "BRIGHT_DATA_USERNAME=${{ secrets.BRIGHT_DATA_USERNAME }}" >> .env
          echo "BRIGHT_DATA_PASSWORD=${{ secrets.BRIGHT_DATA_PASSWORD }}" >> .env
          echo "TELEGRAM_BOT_TOKEN=${{ secrets.TELEGRAM_BOT_TOKEN }}" >> .env
          echo "TELEGRAM_CHAT_ID=${{ secrets.TELEGRAM_CHAT_ID }}" >> .env
          

          tar czf deploy.tar.gz \
            --exclude='.git' \
            --exclude='.github' \
            --exclude='*.pyc' \
            --exclude='__pycache__' \
            LICENSE README.md main.py bright_data_proxy.py telegram_reporter.py run_scraper.sh requirements.txt schema.sql monitoring.sql .env \
            scrapers/

          scp -i ~/.ssh/deploy_key deploy.tar.gz ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_IP }}:/var/www/scraper/
          ssh -i ~/.ssh/deploy_key ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_IP }} '
            cd /var/www/scraper && 
            tar xzf deploy.tar.gz &&
            rm deploy.tar.gz &&
            mkdir -p logs &&
            chmod 600 .env
            chmod +x run_scraper.sh
          '